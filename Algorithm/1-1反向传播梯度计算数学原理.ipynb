{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1原始值\n",
      "[[ 1.73568946 -2.04982601  0.28145959 ..., -1.13443404  0.68300667\n",
      "   1.42170093]\n",
      " [ 0.51851583  1.50134206  0.27935965 ..., -0.75320102 -0.30947899\n",
      "   0.58497344]\n",
      " [-1.02371134  0.51891446  0.24558025 ...,  0.90321667 -0.40254195\n",
      "  -2.71512285]\n",
      " ..., \n",
      " [ 0.28446504  0.54274203 -1.05327363 ...,  0.01385676 -0.63412568\n",
      "  -0.54913508]\n",
      " [-0.34225015  0.09437848  0.7653551  ...,  1.33508807  0.46340405\n",
      "  -0.55351813]\n",
      " [ 0.78193177  0.54755889  1.22685137 ..., -0.80965175 -0.89044055\n",
      "   1.02354888]]\n",
      "0 27298852.3948\n",
      "1 20335580.1486\n",
      "2 17268510.9078\n",
      "3 15316200.2658\n",
      "4 13382302.0626\n",
      "5 11091944.744\n",
      "6 8665064.59308\n",
      "7 6385683.57045\n",
      "8 4529070.47976\n",
      "9 3140157.71224\n",
      "10 2173703.40529\n",
      "11 1521967.85936\n",
      "12 1091263.23755\n",
      "13 805185.15173\n",
      "14 612875.773264\n",
      "15 480290.74265\n",
      "16 386295.881886\n",
      "17 317359.384051\n",
      "18 265230.833673\n",
      "19 224660.196825\n",
      "20 192278.591867\n",
      "21 165943.051033\n",
      "22 144154.749272\n",
      "23 125898.654612\n",
      "24 110436.698902\n",
      "25 97227.8005404\n",
      "26 85859.0092702\n",
      "27 76022.3932979\n",
      "28 67471.0588756\n",
      "29 60007.4480684\n",
      "30 53497.7386395\n",
      "31 47801.3136171\n",
      "32 42784.7473924\n",
      "33 38357.4388195\n",
      "34 34442.9472316\n",
      "35 30973.8360955\n",
      "36 27894.788688\n",
      "37 25155.3757106\n",
      "38 22715.6331878\n",
      "39 20539.360799\n",
      "40 18593.8725193\n",
      "41 16852.6912427\n",
      "42 15291.7918177\n",
      "43 13887.2877746\n",
      "44 12625.0924537\n",
      "45 11490.0805834\n",
      "46 10467.693971\n",
      "47 9546.38040822\n",
      "48 8714.71234899\n",
      "49 7963.19846459\n",
      "w1训练结果\n",
      "[[ 1.70930341 -2.06526174  0.21070305 ..., -1.10940877  0.64294507\n",
      "   1.42292153]\n",
      " [ 0.52600269  1.47844056  0.33750946 ..., -0.68304651 -0.29906446\n",
      "   0.629918  ]\n",
      " [-1.02045633  0.51528732  0.33281015 ...,  0.796476   -0.41978732\n",
      "  -2.70688162]\n",
      " ..., \n",
      " [ 0.25890613  0.5754225  -1.1592564  ...,  0.1016154  -0.6664506\n",
      "  -0.50185599]\n",
      " [-0.35873273  0.08843332  0.78054538 ...,  1.32915714  0.45017745\n",
      "  -0.53547735]\n",
      " [ 0.80317746  0.57229687  1.22750921 ..., -0.81275909 -0.93140472\n",
      "   0.98003448]]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    " \n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    " \n",
    "# Create random input and output data\n",
    "x = np.random.randn(N, D_in)\n",
    "y = np.random.randn(N, D_out)\n",
    " \n",
    "# Randomly initialize weights\n",
    "w1 = np.random.randn(D_in, H)\n",
    "w2 = np.random.randn(H, D_out)\n",
    "print(\"w1原始值\")\n",
    "print(w1)\n",
    " \n",
    "learning_rate = 1e-6\n",
    "for t in range(50):\n",
    "    # Forward pass: compute predicted y\n",
    "    h = x.dot(w1)\n",
    "    h_relu = np.maximum(h, 0)\n",
    "    y_pred = h_relu.dot(w2)\n",
    " \n",
    "    # Compute and print loss\n",
    "    loss = np.square(y_pred - y).sum()\n",
    "    print(t, loss)\n",
    " \n",
    "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.T.dot(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.dot(w2.T)\n",
    "    grad_h = grad_h_relu.copy()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.T.dot(grad_h)\n",
    " \n",
    "    # Update weights\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2\n",
    "    \n",
    "print(\"w1训练结果\")\n",
    "print(w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
